'use client'

import { useState, useRef, useEffect } from 'react'
import { Button } from './ui/button'
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from './ui/card'
import { Avatar, AvatarFallback } from './ui/avatar'
import { Badge } from './ui/badge'
import { Input } from './ui/input'
import { ScrollArea } from './ui/scroll-area'
import { ArrowLeft, Mic, MicOff, Send, Volume2, Heart, Baby, User, Stethoscope } from 'lucide-react'
import { useCommand } from '../contexts/CommandContext'

interface AIContact {
  id: string
  name: string
  avatar?: string
  personality: string
  description: string
  isDefault: boolean
  lastMessage?: string
  lastActive?: Date
  messageCount: number
}

interface Message {
  id: string
  type: 'user' | 'ai'
  content: string
  timestamp: Date
  isVoice?: boolean
}

interface AIChatProps {
  aiContact?: AIContact
  onBack?: () => void
  onBackToMenu?: () => void
  onUpdateLastMessage?: (message: string) => void
}

export function AIChat({ aiContact, onBack, onBackToMenu, onUpdateLastMessage }: AIChatProps) {
  
  const defaultAIContact: AIContact = {
    id: 'default',
    name: 'Tr·ª£ l√Ω AI',
    avatar: 'ü§ñ',
    personality: 'T·∫≠n t√¢m, ki√™n nh·∫´n v√† th√¢n thi·ªán',
    description: 'Tr·ª£ l√Ω AI cho ng∆∞·ªùi cao tu·ªïi',
    isDefault: true,
    messageCount: 0
  }

  const currentAIContact = aiContact || defaultAIContact

  const [messages, setMessages] = useState<Message[]>([
    {
      id: '1',
      type: 'ai',
      content: getWelcomeMessage(currentAIContact),
      timestamp: new Date(),
    }
  ])
  const [inputText, setInputText] = useState('')
  const [isListening, setIsListening] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [microphonePermission, setMicrophonePermission] = useState<'granted' | 'denied' | 'pending'>('pending')
  const [speechError, setSpeechError] = useState<string | null>(null)
  const [interimTranscript, setInterimTranscript] = useState('')
  const [finalTranscript, setFinalTranscript] = useState('')

  const recognitionRef = useRef<any>(null)
  const speechSynthesisRef = useRef<SpeechSynthesis | null>(null)
  const messagesContainerRef = useRef<HTMLDivElement>(null)
  const scrollAreaRef = useRef<HTMLDivElement>(null)

  useEffect(() => {
    if (typeof window !== 'undefined') {
      speechSynthesisRef.current = window.speechSynthesis
    }
  }, [])

  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight
    }
  }, [messages])
  
  useEffect(() => {
    if (scrollAreaRef.current) {
      scrollAreaRef.current.scrollTop = scrollAreaRef.current.scrollHeight
    }
  }, [messages])

  useEffect(() => {
    let latestFinalTranscript = ''

    const initializeSpeechRecognition = async () => {
      try {
        if (typeof window === 'undefined' || !('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
          setSpeechError('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i')
          return
        }

        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
          stream.getTracks().forEach(track => track.stop())
          setMicrophonePermission('granted')
          setSpeechError(null)
        } catch {
          setMicrophonePermission('denied')
          setSpeechError('Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p microphone. Vui l√≤ng c·∫•p quy·ªÅn trong c√†i ƒë·∫∑t tr√¨nh duy·ªát.')
          return
        }

        const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition
        recognitionRef.current = new SpeechRecognition()
        recognitionRef.current.continuous = true
        recognitionRef.current.interimResults = true
        recognitionRef.current.lang = 'vi-VN'

        recognitionRef.current.onresult = (event: any) => {
          let interim = ''
          let final = ''
          for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript
            if (event.results[i].isFinal) {
              final += transcript
            } else {
              interim += transcript
            }
          }
          latestFinalTranscript += final
          setInterimTranscript(interim)
          setFinalTranscript(latestFinalTranscript)
        }

        recognitionRef.current.onerror = (event: any) => {
          console.error('Speech recognition error:', event.error)
          setIsListening(false)
          switch (event.error) {
            case 'not-allowed':
              setSpeechError('Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p microphone. Vui l√≤ng c·∫•p quy·ªÅn v√† th·ª≠ l·∫°i.')
              setMicrophonePermission('denied')
              break
            case 'no-speech':
              setSpeechError('Kh√¥ng ph√°t hi·ªán gi·ªçng n√≥i. Vui l√≤ng th·ª≠ l·∫°i.')
              break
            case 'audio-capture':
              setSpeechError('Kh√¥ng th·ªÉ truy c·∫≠p microphone. Ki·ªÉm tra k·∫øt n·ªëi microphone.')
              break
            case 'network':
              setSpeechError('L·ªói m·∫°ng. Ki·ªÉm tra k·∫øt n·ªëi internet.')
              break
            default:
              setSpeechError('L·ªói nh·∫≠n di·ªán gi·ªçng n√≥i. Vui l√≤ng th·ª≠ l·∫°i.')
          }
        }

        recognitionRef.current.onend = () => {
          setIsListening(false)
          const text = latestFinalTranscript.trim()
          if (text) {
            setInputText(text)
          }
          latestFinalTranscript = ''
          setFinalTranscript('')
          setInterimTranscript('')
        }

      } catch (error) {
        console.error('Error initializing speech recognition:', error)
        setSpeechError('Kh√¥ng th·ªÉ kh·ªüi t·∫°o nh·∫≠n di·ªán gi·ªçng n√≥i')
      }
    }

    initializeSpeechRecognition()

    return () => {
      if (recognitionRef.current) recognitionRef.current.stop()
    }
  }, [])

  function getWelcomeMessage(ai: AIContact): string {
    return `Ch√°u ch√†o b√°c ·∫°! Ch√°u l√† m·ªôt tr·ª£ l√Ω AI, kh√¥ng c√≥ t√™n ri√™ng ƒë√¢u ·∫°. B√°c c√≥ th·ªÉ g·ªçi ch√°u l√† "tr·ª£ l√Ω" ho·∫∑c "b·∫°n ƒë·ªìng h√†nh" c≈©ng ƒë∆∞·ª£c ·∫°.\n\nCh√°u ·ªü ƒë√¢y ƒë·ªÉ gi√∫p ƒë·ª° b√°c m·ªçi vi·ªác, t·ª´ tr·∫£ l·ªùi c√¢u h·ªèi, tr√≤ chuy·ªán, cho ƒë·∫øn h·ªó tr·ª£ nh·ªØng c√¥ng vi·ªác nh·ªè nh·∫∑t kh√°c. N·∫øu c√≥ g√¨ c·∫ßn ch√°u gi√∫p, b√°c c·ª© n√≥i nh√©. Ch√°u lu√¥n s·∫µn l√≤ng ·∫°.`
  }

  const startListening = () => {
    if (microphonePermission === 'denied') {
      setSpeechError('Vui l√≤ng c·∫•p quy·ªÅn microphone trong c√†i ƒë·∫∑t tr√¨nh duy·ªát v√† t·∫£i l·∫°i trang')
      return
    }

    if (recognitionRef.current && !isListening) {
      try {
        setIsListening(true)
        setSpeechError(null)
        setFinalTranscript('')
        setInterimTranscript('')
        recognitionRef.current.start()
      } catch (error) {
        console.error('Error starting speech recognition:', error)
        setIsListening(false)
        setSpeechError('Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán gi·ªçng n√≥i')
      }
    }
  }

  const stopListening = () => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop()
      setIsListening(false)
    }
  }

  const speakText = (text: string) => {
    if (speechSynthesisRef.current && text) {
      speechSynthesisRef.current.cancel()
      const utterance = new SpeechSynthesisUtterance(text)
      utterance.lang = 'vi-VN'
      utterance.rate = 0.9
      utterance.pitch = 1
      utterance.volume = 0.8
      utterance.onstart = () => setIsSpeaking(true)
      utterance.onend = () => setIsSpeaking(false)
      utterance.onerror = () => setIsSpeaking(false)
      speechSynthesisRef.current.speak(utterance)
    }
  }

  const getAIResponse = async (prompt: string): Promise<string> => {
    try {
      const response = await fetch("/chat", {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ prompt })
      })
      const data = await response.json()
      return data || 'T√¥i kh√¥ng hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n kh√¥ng?'
    } catch (error) {
      console.error('L·ªói g·ªçi AI API:', error)
      return 'ƒê√£ x·∫£y ra l·ªói khi k·∫øt n·ªëi v·ªõi AI. Vui l√≤ng th·ª≠ l·∫°i sau.'
    }
  }

  const handleSendMessage = async (messageContent?: string) => {
    const content = messageContent || inputText.trim()
    if (!content) return
    const userMessage: Message = {
      id: Date.now().toString(),
      type: 'user',
      content,
      timestamp: new Date(),
    }

    setMessages(prev => [...prev, userMessage])
    setInputText('')

    const AIResponse = await getAIResponse(content)
    const AIMessage: Message = {
      id: (Date.now() + 1).toString(),
      type: 'ai',
      content: AIResponse.reply,
      timestamp: new Date(),
    }

    if (AIResponse.command) {
        excuteCommand(AIResponse.command)
    }
    
    setMessages(prev => [...prev, AIMessage])
    if (onUpdateLastMessage) {
      onUpdateLastMessage(AIResponse)
    }
  }

  const handleBack = onBack || onBackToMenu

  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 via-white to-green-50 p-4">
      <div className="max-w-4xl mx-auto space-y-6">
        {/* Header */}
        {onBackToMenu && (
          <div className="flex items-center gap-4 bg-white/80 backdrop-blur-sm rounded-2xl p-4 shadow-sm border border-white/20">
            <Button
              variant="ghost"
              size="sm"
              onClick={onBackToMenu}
              className="text-gray-600 hover:text-gray-900"
            >
              <ArrowLeft className="w-4 h-4 mr-2" />
              Quay l·∫°i Menu
            </Button>
            <h1 className="text-xl font-medium text-gray-800">AI Tr·ª£ L√Ω</h1>
          </div>
        )}
        <div className="space-y-6">
        {/* Header */}
        <Card>
          <CardHeader>
            <div className="flex items-center gap-4">
              <Button variant="outline" size="sm" onClick={handleBack}>
                <ArrowLeft className="w-4 h-4" />
              </Button>

              <Avatar className="w-12 h-12">
                <AvatarFallback className="text-xl">
                  {currentAIContact.avatar || 'ü§ñ'}
                </AvatarFallback>
              </Avatar>

              <div className="flex-1">
                  <div className="flex items-center gap-2">
                    <CardTitle className="text-lg">{currentAIContact.name}</CardTitle>
                  </div>
                <CardDescription>{currentAIContact.description}</CardDescription>
              </div>
            </div>
          </CardHeader>
        </Card>

        {/* Chat Interface */}
        <Card>
          <CardContent className="p-4">
            {/* Chat Messages */}
            <div ref={scrollAreaRef} className="h-96 mb-4 border rounded-lg p-4 space-y-4 overflow-y-auto">
              <div className="space-y-4">
                {messages.map((message) => (
                  <div
                    key={message.id}
                    className={`flex gap-3 ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
                  >
                    {message.type === 'ai' && (
                      <Avatar className="w-8 h-8">
                        <AvatarFallback className="text-sm">
                          {currentAIContact.avatar || 'ü§ñ'}
                        </AvatarFallback>
                      </Avatar>
                    )}

                    <div className={`max-w-xs lg:max-w-md ${message.type === 'user' ? 'order-first' : ''}`}>
                      <div
                        className={`rounded-lg px-4 py-2 ${
                          message.type === 'user'
                            ? 'bg-blue-100 text-blue-700'
                            : 'bg-gray-100 text-gray-900'
                        }`}
                      >
                        <p className="text-sm">{message.content}</p>
                        {message.type === 'ai' && (
                          <Button
                            onClick={() => speakText(message.content)}
                            variant="ghost"
                            size="sm"
                            className="mt-2 h-6 p-1 text-xs"
                          >
                            <Volume2 className="w-3 h-3" />
                            Ph√°t √¢m
                          </Button>
                        )}
                      </div>
                      <p className="text-xs text-muted-foreground mt-1">
                        {message.timestamp.toLocaleTimeString('vi-VN', {
                          hour: '2-digit',
                          minute: '2-digit',
                        })}
                      </p>
                    </div>

                    {message.type === 'user' && (
                      <Avatar className="w-8 h-8">
                        <AvatarFallback className="bg-green-100 text-green-600 text-sm">
                          B·∫°n
                        </AvatarFallback>
                      </Avatar>
                    )}
                  </div>
                ))}
              </div>
            </div>

            {/* Voice Listening Status */}
            {isListening && (
              <div className="mb-4 p-3 bg-green-50 border border-green-200 rounded-lg">
                <div className="flex items-center gap-2">
                  <div className="w-2 h-2 bg-green-500 rounded-full animate-pulse"></div>
                  <span className="text-sm text-green-700">ƒêang nghe... H√£y n√≥i ƒëi·ªÅu b·∫°n mu·ªën</span>
                </div>
              </div>
            )}

            {/* Input Area */}
            <div className="flex flex-col items-center gap-4 mt-4">
              {/* Mic Button */}
              <Button
                onClick={() => (isListening ? stopListening() : startListening())}
                className="w-18 h-18 rounded-full shadow-lg"
                variant={isListening ? "destructive" : "outline"}
              >
                {isListening ? <MicOff className="w-24 h-24" /> : <Mic className="w-24 h-24" />}
              </Button>
              <span className="text-xs text-muted-foreground">
                {isListening ? 'ƒêang nghe...' : 'Nh·∫•n ƒë·ªÉ b·∫Øt ƒë·∫ßu n√≥i'}
              </span>

              {/* Text Input and Send */}
              <div className="flex w-full gap-2">
                <Input
                  value={inputText}
                  onChange={(e) => setInputText(e.target.value)}
                  placeholder={`Nh·∫Øn tin v·ªõi ${currentAIContact.name}...`}
                  onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
                  className="flex-1"
                />
                <Button onClick={() => handleSendMessage()} disabled={!inputText.trim()}>
                  <Send className="w-4 h-4" />
                </Button>
              </div>
            </div>

            {/* AI Personality */}
            <div className="mt-4 p-3 bg-blue-50 border border-blue-200 rounded-lg">
              <p className="text-sm text-blue-700">
                <strong>T√≠nh c√°ch:</strong> {currentAIContact.personality}
              </p>
          </div>
          </CardContent>
        </Card>
      </div>
    </div>
  </div>
  )
}